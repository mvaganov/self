<img src="http://www.codegiraffe.com/calcpersecond.png" height = 500>

# Michael's Vision

I want to prepare people for [dramatically-powerful-computer-technology-in-the-near-future](http://www.codegiraffe.com/singularity.png). [I've done that as a dedicated Computer Science teacher](whylearncs.md) for many years, and [I keep finding great opportunities to do it](https://www.applied-computing.org/) even as a full time software engineer. I also want to help break cycles of addiction in young gamers, which is an immidiate demographic problem. I also want to develop intelligence-multiplying software, like accessible automation, tools for analysis of human problems, design tools to reduce engineering burden, self-organization/participatory-governance, and benevolent AI that guides humans to achieve human goals. I have a succession of specific software projects in mind.

### Why did I teach software development for so long?

Regardless of your opinion on [the](https://singularityhub.com/2015/01/26/ray-kurzweils-mind-boggling-predictions-for-the-next-25-years/) [technological](http://www.kurzweilai.net/blog) [singularity](https://en.wikipedia.org/wiki/Technological_singularity), the fact that powerful-computing-technology is coming is very clear. More technology-experts, ideally well-adjusted and un-addicted, participating in society, will make us all safer from, and *with*, these technology tools. We need more tech experts. Need. More.

## Prophecy of the Future

As computer-technology improves, many (possibly most) people won't be able to find productive work. Computer-controlled tools will be able to do almost every task a human does, but better in many ways, certainly more cheaply. Some humans will have computer-assisted jobs, taking advantage of hardware and software to multiply job effectiveness, letting one person do the job of *millions*. Automation will duplicate effort for free, while electronic communication will eliminate the need for duplication of effort, embeded sensors will track resources and reduce waste, electronic documentation will educate on-the-fly, and more. It's already happening, it will just happen more in the future. The effectiveness of these tools will encourage more of these tools, and help develop more of these tools. It will be a virtuous circle, for the people using the tools.

In the near future (2030s?), people with the right tech skills will be able to learn *significantly* faster than a normal person, and have more mental output, in both quantity and even quality (a greater-than-10x multiplier is a reasonable guess). Imagine doing any arithmetic problem without ever needing to touch a physical calculator, or commiting something to perfect memory as you are listening to it, or communicating with any person, in any language, without speaking or writing words, or even holding a device. This will be possible with tools like [Alter Ego from MIT](https://www.media.mit.edu/projects/alterego/overview/).

Imagine having an idea in the shower for how to write that next assignment, and before you've gotten out of the shower, you've dicated a first draft, without saying a word. Imagine hearing an interesting idea during a conversation, immidiately searching for a podcast, cutting to relevant new knowledge in the audio, listening to it at double speed (or more), and then responding during a conversation, with that new knowledge in mind. How would that change retail? How would that change education? How would that change political discourse?

The next revolution will not just be about what is possible, but where those possiblities will insert themselves in our lives. Within seconds of hearing an initiating idea, while continuously engaged in other tasks, you'll be able to have a machine do research and organization tasks for you on the back end. This will be possible by applying some (probably significant but certainly achievable) machine learning and project management to Alter Ego.

Now imagine tech entrepreneurs using these technologies to unceasingly brainstorm, collaborate, and develop new mind-engagement tools. We know how radio and television sped up society, what will be the effect of an information interface like real-time [Augmented-Reality](https://www.youtube.com/watch?v=un4MmLZh9-g) [glasses](https://www.youtube.com/watch?v=mrXjGBsICuc)? What will be the effect of direct brain-to-computer input-and-output enabled by [real-time brain imaging](https://www.ted.com/talks/mary_lou_jepsen_how_we_can_use_light_to_see_deep_inside_our_bodies_and_brains?language=en)? These proofs of concept are being actively developed, and will be cheap to mass-produce in our lifetimes. 2030s is not a stretch.

Humans who know-how-to-use-computers-to-multiply-effort will seem like another class of human (like *wizards*). They'll be employable.

### What If I'm not a Wizard?

**"Impetus AR"** - Imagine a real-time re-education tool that will turn a population of disenfranchised meat-bags into a productive, organized work force. It's an Augmented Reality (AR) system that points a person toward productive actions, hopefully that benefit the causes they are aligned with. It gives someone a thing to do, something they believe in, and keeps them moving. Imagine a MMORPG quest overlay, but in real life.

The system identifies tasks, directs users to tools and resources with visual/auditory/haptic cues, educates users with tutorials in Augmented Reality space, logs the completion of tasks, and coordinates great acts done by many people doing small deeds. Tutorials will eventually be created in real-time by neural-networks, to match specific real-life conditions, after enough human-made tutorials can be data-mined.

Step-by-step-instructions will be given to anyone who doesn't know what to do next. Imagine not knowing how to bake a cake (or even knowing that now is a good time to bake a cake), but your glasses recognize the kitchen you are in, and talk you through the process, and even guide you to where to put the cake when you're done.

Impetus AR will be like some of the tools used by wizards to educate quickly, but more consumable by people without strong computer skills or disciplined technical drive. Impetus AR is primarily an interface with users as consumers, who don't have the personal intention to be creators. Impetus AR would direct people, nullifying some human autonomy, in ways that the developer tools won't. A lot of people will be OK with this, because a lot of people don't like thinking for themselves. This means that the drive to be creative at all will become a differentiating factor in productivity. Being a wizard will hinge in the strength-of-will to create.

The organization of who-does-what-task with-what-resources will be organized by another system. 

### Who or what will do the organizing?

**"Impetus Jobs"** - Imagine a combination of LinkedIn, TaskRabbit, SimAnt, Civilization, Slack, Reddit, and AlphaZero. It will simulate people "in silico", gather and communicate with people, provide tools for communal decision making, use Strong-AI-prediction/analysis to develop plans for big groups to accomplish their collective goals, and balance work-load for high probability of gestalt success, for the entire population.

Impetus Jobs will have have information about citizens as a workers, including their skills, preferred kinds of work, possible moral/ethical perspectives, and life-goals. Facebook has already done much of this work, and it is only going to get easier to do with time. Impetus Jobs will need social-media integration, if only to keep mining this kind of data. Workers will be matched with tasks, with worker advancement and "fit" in-mind. Tutorial tasks will be identified to improve skills if needed, with advancement tracks laid out as videogame-like tech-trees.

The primary role of Impetus Jobs will be a database of workers and work-to-do. Impetus Jobs will have machine learning algorithms that evaluate which people are suited for which role, and combined with details about how to manage projects, it will tell Impetus AR to connect them.

### Where will the project management come from?

**"Impetus Project"** - There are some project management tools out there in the direction of Impetus Project. I'm a fan of the task-management tool called ClickUp, and another called AirTable, which show task data in multiple views. I'd like to add a few narrative mechanics, and game-like visulaizations & interfaces, like you might find in a Real Time Strategy game. Compelling-visualizations and auditable advancement will probably encourage engagement in the people monitoring projects with this tool. Consistent organic engagement seems to be the peice that is missing from modern ERP tools, and I suspect game development techniques will improve engagement and motivation.

My own prototypes for this software have focused on visualizations, like morphing task diagrams, including TODO lists (which can be broken down into sub-lists of step-by-step instructions as work-breakdown-structures), morphing into GANTT charts (which allow tasks to be tracked as tiered progress bars), or morphing into burndown charts (which visualize project completion rates over time). I've been working on a rich spread-sheets to track resources & personnel, but it might make sense to just use existing web tools web tools (or maybe give my visualization demos to them).

Impetus Project should also do predictive-analysis of projects using simulation AI to improve estimation. I'm imagining a game-like agent-based model. That AI sohuld be built to have human-like cognitive bias in mind, which can be tuned by real data mined from actual human performance. "Strong-AI" simulation may not be cheap enough for huge agent-based models. Maybe a strong AI can design the agent based models? The visualizations, data models, and project-specific user interfaces for Impetus Project will sit in a real-time strategy game.

### Wait, what about the Augmented Reality piece, what will mature AR tools enough to build AR tutorials?

**"Builder VR"** - Think of this as *Minecraft-For-Real-Life*, teaching players to build structures with simulated foundations and connections to plumbing/sewage/electrical-grids/gas-lines, building around simulated geography, using simulated construction materials like planks, and rebar, and poured concrete, with context-sensitive building-code overlays, letting people practice building realistic modern buildings with only simulated physical costs. Or we could make fantasy castles for dragons.

Useful tutorials using VR are being developed in this space. An excellent domain for these tutorials is Residential-Construction/Contracting. This industry has demand for a product like that, to enhance training and professionalism of it's workers. Anyone who has observed home addition budgets and schedules knows there is a need for this. The success of Minecraft indicates that there is a shared mental-itch for this building idea in the population even outside the industrial value, at least in a simplified state.

### Could a game form a structure for project management software?

**"Galactus"** - A real-time strategy game about seeking out partner-agents, with diverse skill sets and personalities (including simplified ethics and cognitive biases), to accomplish complex goals. Think SimAnt combined with Pathfinder Kingmaker and Crusader Kings 2. The game mechanics will be implemented in an agent-based simulation. An AI system based on expert systems and behavior-trees emulating cognitive biases, and simplified ethics based on a computerized ethics-evaluation system. I'm developing one called ["Ethos"](http://codegiraffe.com/qeval/qual.html), which is informed by the "Big 5" personality traits system, adjusted with my own perspective, and colored by a moral compass from a High School I used to teach at.

In the game, the player will influence the behavior of agents, like the god-games from Bullfrog in the 90s (Dungeon Keeper, Black and White). Goal-objects will be discovered and worked by an agent's skills. An agent working a skill improves the agent's skill score, which allows more complex goals to be completed later. Some goals have a resource requirements and dependency-graphs that force sub-goals to be accomplished first, sometimes in complex sequences. Agents recruit partner-agents with complementary skills and personalities to accomplish complex goals. This is done in an eco-system of other agent groups, who are all seeking to accomplish their own goals (sometimes conflicting or complementary) as well. This game will be a clear set of intellectual models for Impetus Project.

### How will human ethics be modeled in a game again? That seems like a hard AI problem...

[**"Ethos"**](http://codegiraffe.com/qeval/qual.html) - A system that users can use to recognize areas of personal ethical growth. I've designed it while studying human psychology, and various religious texts (primarily Christianity and Buddhism). It was originally developed as an evaluation system for students, as a competitor to the standard academic A-through-F grade system.

There is more work to do here as well, but doing this work could have important implications on the future of strong AI. Imagine what a relief it would be to the tech world if a computer could systemize what it means to be 'good'. Developing a deep framework to help a machine identify what is right and wrong behavior is an important next-step in humanity's advancement on the grand tech tree.

### That's a lot to think about...

***"My Dragon"*** - The name I use to refer to these ideas.

*Ethos* is a moraly lofty goal, but seems like a good framework for implementing socially-constructive gameplay features in *Galactus* and *Builder VR*, and a necessary framework for the strong-AI in *Impetus Jobs*.

Developing *Galactus* or *Builder VR* as a game first could be sociologically valuable for young people, who are a risk to society when they don't integrate into works larger than themselves, which seems to be a demographic problem today. The game aspect could engage them long enough to teach good mental models for engagement In Real Life. Sadly, game development is not a lucrative industry. However, enterprise software is.

*Impetus Project* is the commercial-training/enterprise software version of *Galactus*, selling a higher-profit-price-point version of that game to businesses/governments. The sales pitch could be "Many of your young employees *already know* this user interface, and they enjoy it. Your future workforce is ready, if you use these tools." Engagement problems, due to learning-curve, user-interface, and lack-of-fun, tend to be problems with enterprise-software and training-software; *Impetus*'s roots (the games focus) should address these problems nicely.

I think *Galactus*, *Builder VR*, and *Impetus Project* are all doable with today's technology (2017).

*Impetus Jobs* is a natural evolution of *Impetus Project*: integrate social-media and job-boards, apply machine learning. I think *Impetus Jobs* needs some auditable machine-learning and machine-based creatively-constrained-decision-making techniques. I've got an idea for an ensemble machine-learning technique I'm toying with (Suffrag Ex Machina), based on Ranked-Choice (or Instant-Runoff) Voting. I imagine machine-decision-making-techniques like that will be developed and used by more people around 2022.

*Impetus AR* will need cheap AR hardware, very mature machine-vision (google mediapipe is headed there), and significant amounts of AR-enhanced dynamic tutorial content (which *Builder VR* can act as a scaffolding set of examples for). My guess is that *Impetus AR* will be commercially, and probably industrially infeasible untill around 2025, because cheap-and-good AR glasses need to be available en-masse (lightweight, eye tracking, VR compatable). AI that generates dynamic tutorial content seems like a tricky problem too, but I think it will become tractable with better generative-machine-learning algorithms, probably also in the 2025 timeframe.

I want to see these tools happen. Not having these tools in the near future seems like a really bad idea for humanity.

## Specific Short-term Goals
(This is essentially a public TODO list, most people reading the manifesto can stop here. Even me, this list is out of date. TODO: update this list)

### Code Resources for Teaching & My Dragon
  * [Nonstandard Assets](https://github.com/mvaganov/galactus/tree/master/galactus/Assets/Nonstandard%20Assets) - a complimentary API to Unity providing common useful tools, which will be used in the other software projects.
    * Lines, Timer, Proc, CubeTools (3D math library)
    * CmdLine - a true command-line terminal replacement within Unity, including TTY color and position adjustment (TODO)
    * OMU - Object Modeling for Unity script (serialize/deserialize arbitrary data in JSON-like form)
    * Noisy - re-doing PhysSound. Would be nice to get VoiceSynthesis in here too
    * "Story" Dialog system / scripted sequenced UI system
    * reflective object UI generator

### My Dragon (Galactus & Builder VR)
* Nonstandard Assets
* 3D math code (command zones, AI, 3D voronoi, navmesh pathfinding)
  * in development in Unity3D. finding a good 3D-voronoi library would help a lot.
* spreadsheet UI
  * in development in Unity3D, with functional scripting engine. I just need to get this done. I'll probably open-source it when I do.
* Instant Runoff Voting tools (multiplayer decision making, AI)
  * need to convert .js code to C#, develop visuals, probably share that as a stand-alone data visualization app.
  * wrap around multiple ANN to create a recursive-ensemble technique (Sufrag Ex Machina)
* dynamic stat system
  * using common scripting system also used by spreadsheet UI may not scale well to thousands of objects. If I can generate C# objects with a runtime compiler, I'll have to create and use properties to replicate callback behavior around property updates.
* General AI (state-machines, steering behaviors)
  * should find a good API someone else wrote and add 3D math code to it. would be nice to find someone who is a pro at this.
* artifact building
  * agent can build roads, barriers, caches, monuments. need to fully spec this out in a design doc.
* VR controls
  * more experimentation required, need to integrate into movement/control UI. need to bone-up on VR UI standards, or find an expert. Maybe VRTK 4.0 will solve this?
* scripting system
  * need to make imperative code in OMU more java-script like, and light enough to dissuade programming. the script should be declarative, and use functional patterns if scripting is needed
* Project & Task system
  * use the scripted JSON-like datastructures (OMU) as the base. Already have examples of this working.
* Personnel & Resource system
  * requires spreadsheet UI, scripts, and stat/trait system for personnel to inform AI simulation. The RankedVote visual will help show and make-decisions-about resource/personnel usage.
* Project Management Visualizations (WBS, GANTT, burndown)
  * refresh and import old code.
* Customization UI
  * need to find and implement color picker, sprite loader/picker, simple model generator and basic texture mapper.
* Builder VR demo
  * this needs many more sub-bullet points
