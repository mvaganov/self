<img src="http://www.codegiraffe.com/calcpersecond.png" height = 500>

# Mr. V's Manifesto

In preparation for [dramatically-powerful-computer-technology-in-the-near-future](http://www.codegiraffe.com/singularity.png), my short-term goal is to teach software development, especially to influential young people. My long-term goal is to help develop software to get mankind to organize itself better, with transparent tools for participatory governance, and benevolent AI that guides humans to achieve human goals. I have a succession of specific software projects in mind.

### Why "Teach Software Development" in the Short Term?

Regardless of your opinion on [the](https://singularityhub.com/2015/01/26/ray-kurzweils-mind-boggling-predictions-for-the-next-25-years/) [technological](http://www.kurzweilai.net/blog) [singularity](https://en.wikipedia.org/wiki/Technological_singularity), the fact that powerful-computing-technology is coming is very clear. More technology-experts participating in society will make us all safer from, and *with*, these tools.

I also want to teach software development because [I believe it creates better 21st-century people](whylearncs.md). <--link to details

## Prophecy of the Future

As computer-technology improves, many (possibly most) people won't be able to find productive work. Computer-controlled tools will be able to do almost every task a human does, but better in many ways, certainly more cheaply. Humans will have computer-assisted jobs, taking advantage of hardware and software to multiply job effectiveness, letting one person do the job of *millions*. Automation will duplicate effort for free, while electronic communication will eliminate the need for duplication of effort, embeded sensors will track resources and reduce waste, electronic documentation will educate on-the-fly, and more. It's already happening, it will just happen more in the future.

In the future, conservatively, people with the right tech skills will be able to learn at double the speed of a normal person, and have double the mental output, in both quantity and quality (a greater-than-10x multiplier might be more accurate). Imagine doing any arithmetic problem without ever needing to touch a calculator, or commiting something to perfect memory as you are listening to it, or speaking with any person, in any language, without speaking or writing words, or holding a device. This will be possible with tools like [Alter Ego from MIT](https://www.media.mit.edu/projects/alterego/overview/).

Imagine having an idea in the shower for how to write that next assignment, and before you've gotten out of the shower, you've dicated a first draft, reviewed it, and edited it down for brevity. Imagine hearing an interesting idea, immidiately searching for a podcast, cutting to relevant new knowledge in the audio, listening to it at double speed (or more), and then responding with that new knowledge in mind, all within seconds of hearing the initiating idea, while continuously engaged in other tasks, like walking, driving, or conversation. This will be possible by applying a little machine learning to Alter Ego.

Now imagine tech entrepreneurs using that technology to unceasingly brainstorm, collaborate, and develop new mind-engagement tools. We know how radio and television sped up society, what will be the effect of an information interface like real-time [Augmented-Reality](https://www.youtube.com/watch?v=un4MmLZh9-g) [glasses](https://www.youtube.com/watch?v=mrXjGBsICuc)? What will the be the effect of direct brain-to-computer input-and-output enabled by [real-time brain imaging](https://www.ted.com/talks/mary_lou_jepsen_how_we_can_use_light_to_see_deep_inside_our_bodies_and_brains?language=en)?

Humans who know-how-to-use-computers-to-multiply-effort (what I call *wizards*) will be employable.

### What If I'm not a Wizard?

**"Impetus AR"** - a real-time re-education tool that will turn a population of disenfranchised meat-bags into a productive, organized work force. Imagine an Augmented Reality (AR) system that points a person toward productive actions (hopefully that benefit the causes the workers are aligned with). The system identifies tasks, directs users to tools and resources with visual/auditory/haptic cues, educates users on proper use of tools and resources with tutorials, and logs the completion of tasks. Tutorials will eventually be created in real-time by neural-networks, to match real-life conditions, after adapting human-pre-made tutorials. Step-by-step-instructions, along with tool/resource information and metadata, will be fed to the AR system by "Impetus Jobs". Impetus AR will be like some of the tools used by wizards, but more consumable by people without strong computer skills.

### How could this tool be created?

**"Impetus Jobs"** - Imagine a combination of LinkedIn and TaskRabbit, with a Strong-AI-prediction/analysis-tool balancing work-load for maximum probability of success. Impetus Jobs will have have information about a person as a worker, including their skills, preferred kinds of work, simplified moral/ethical perspectives, and life-goals. Workers will be matched with tasks nearby, with worker advancement and "fit" in-mind. Tutorial tasks will be created by the system to improve skills, and work toward accomplishment of ideals and life-goals of the workers. Very large tasks, composed of many subtasks, will be populated by a project-management-software suite, "Impetus Project".

## The software I'm currently developing in this direction as side projects

**"Impetus Project"** - Project-management software that handles arbitrary tasks of arbitrary complexity, resource usage, and personnel. It's a database of work to do, and how to do it. It works with tasks in many different dimensions, including step-by-step instructions as work-breakdown-structures, GANTT charts, burndown charts (for tracking), and resource & personnel spread-sheets. Impetus Project also does predictive-analysis of projects using algorithms that improve estimation with data from past performance (no "strong-AI", that is what Impetus Jobs is for). The data model and user interface for Impetus Project is based on the game "Galactus".

**"Galactus"** - A real-time strategy game about seeking out partner-agents, with diverse skill sets, personalities including simplified ethics, to accomplish complex goals. The game mechanics will be implemented in an agent-based simulation, with much of the AI based on expert systems emulating cognitive biases, and the simplified ethics based on a computerized ethics-evaluation system I'm developing called "Ethos". 

In the agent-based simulation, goal-objects objects are worked by an agent's skills. An agent working a skill improves the agent's skill score, which allows more complex goals to be completed later. Some goals have a dependency-graph that forces sub-goals to be accomplished first, sometimes in complex sequences. Agents recruit partner-agents with complementary skills and personalities to accomplish complex goals. This is done in an eco-system of other agent groups, who are all seeking to accomplish goals (sometimes conflicting or complementary) as well. This game will be a clear set of intellectual models for Impetus Project.

[**"Ethos"**](http://codegiraffe.com/qeval/qual.html) - A system that users can use to recognize areas of personal ethical growth. The system was originally after I was asked to brainstorm an evaluation system for students.

**"Builder VR"** - Think of this as *Minecraft-For-Real-Life*, teaching players to build houses with simulated foundations and connections to plumbing/sewage/electrical-grids/gas-lines, building around simulated geography, using simulated construction materials like planks and poured 'concrete', with context-relevant building-code requirement overlays, letting people practice building realistic modern buildings without physical costs. Before creating Impetus AR, useful tutorials using VR must be developed and tested. An excellent domain for these tutorials would be Residential-Construction/Contracting. This industry has demand for a product like that, to enhance training (and professionalism) of it's workers, and the success of Minecraft indicates that there is a shared mental-itch for this idea in the population.

***"My Dragon"*** - The name you'll hear me use to refer to this plan.

*Ethos* is a moraly lofty goal, but seems like a good framework for implementing socially-constructive gameplay features in Galactus or BuilderVR.

Developing *Galactus* or *Builder VR* as a game first could be sociologically valuable for young people, who are a risk to society when they don't integrate into works larger than themselves. The game aspect could engage them long enough to teach some good mental models for engagement In Real Life (IRL). Sadly, game development is not a lucrative industry. However, enterprise software is.

Once there is a game that is usable as commercial-training/enterprise software, selling a higher-profit-price-point version of that game to more lucrative businesses/governments should be possible. The sales pitch could be "Many of your young employees *already know* this user interface, and they enjoy it. Many more prospective employees are already trained." Learning-curve, user-interface, and lack-of-fun tend to be problems with enterprise-software and training-software, which again, are very commercially viable industries to develop for.

Impetus Jobs is a natural evolution of Impetus Project: integrate social-media and job-boards, apply machine learning.

Impetus AR will need cheap AR hardware, mature machine-vision, and significant amounts of AR-enhanced dynamic tutorial content (which Builder VR can act as a set of examples for).

I think *Galactus*, *BuilderVR*, and *Impetus* are all easily doable with today's technology.

I think *Impetus Project* needs some better machine-learning and creatively-constrained-decision-making techniques than are publicly available (I have an idea about an ensemble technique I'm calling Suffrag Ex Machina that I'm toying with). But I'd imagine those will show up around 2022.

My guess is that Impetus AR will be commercially infeasible untill around 2025, because cheap projector glasses need to be available en-masse. AI that generates dynamic tutorial content seems like a tricky problem too, but I think it will become tractable with better generative-machine-learning algorithms.

## Specific Short-term Goals
(This is essentially a public TODO list, most people reading the manifesto can stop here)

### Teaching
  * [Nonstandard Assets](https://github.com/mvaganov/galactus/tree/master/galactus/Assets/Nonstandard%20Assets) - a complimentary API to Unity providing common useful tools, which will be used in the other software projects.
    * Lines, Timer, ContingencyTrigger, CmdLine, CubeTools (3D math library)
    * ControlledRigidbody (ground, air, space, novel-gravity controls), GravityObject, AIController
    * VR controller (teleport, climb-to-move, waddle-move... VRTK doing all of this?)
    * OMU - Object Modeling for Unity script (serialize/deserialize arbitrary data in JSON-like form)
    * MemoryPool
    * "Story" Dialog system / scripted sequenced UI system
    * reflective object UI generator

### My Dragon (Galactus Phase)
* Nonstandard Assets
* 3D math code (command zones, AI, 3D voronoi, navmesh pathfinding)
  * in development in Unity3D. finding a good 3D-voronoi library would help a lot.
* spreadsheet UI
  * in development in Unity3D, with functional scripting engine. I just need to get this done. I'll probably open-source it when I do.
* Instant Runoff Voting tools (multiplayer decision making, AI)
  * need to convert .js code to C#, develop visuals, probably share that as a stand-alone data visualization app.
  * wrap around multiple ANN to create a recursive-ensemble technique (Sufrag Ex Machina)
* dynamic stat system
  * using common scripting system also used by spreadsheet UI may not scale well to thousands of objects. If I can generate C# objects with a runtime compiler, I'll have to create and use properties to replicate callback behavior around property updates.
* General AI (state-machines, steering behaviors)
  * should find a good API someone else wrote and add 3D math code to it. would be nice to find someone who is a pro at this.
* artifact building
  * agent can build roads, barriers, caches, monuments. need to fully spec this out in a design doc.
* VR controls
  * more experimentation required, need to integrate into movement/control UI. need to bone-up on VR UI standards, or find an expert. Maybe VRTK 4.0 will solve this?
* scripting system
  * need to make imperative code in OMU more java-script like.
* Project & Task system
  * use the scripted JSON-like datastructures (OMU) as the base. Already have examples of this working.
* Personnel & Resource system
  * requires spreadsheet UI, scripts, and stat/trait system for personnel to inform AI simulation. The RankedVote visual will help show and make-decisions-about resource/personnel usage.
* Project Management Visualizations (WBS, GANTT, burndown)
  * refresh and import old code.
* Customization UI
  * need to find and implement color picker, sprite loader/picker, simple model generator and basic texture mapper.
* Builder VR demo
  * this needs many more sub-bullet points
