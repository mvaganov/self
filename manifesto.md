<img src="http://www.codegiraffe.com/calcpersecond.png" height = 500>

# Mr. V's Manifesto

In preparation for [dramatically-powerful-computer-technology-in-the-near-future](http://www.codegiraffe.com/singularity.png), my short-term goal is to teach software development, especially to young people. My long-term goal is to help develop software to get mankind to organize itself better, with transparent tools for participatory governance, and benevolent AI that guides humans to achieve human goals. I have a succession of specific software projects in mind.

### Why "Teach Software Development" in the Short Term?

Regardless of your opinion on [the](https://singularityhub.com/2015/01/26/ray-kurzweils-mind-boggling-predictions-for-the-next-25-years/) [technological](http://www.kurzweilai.net/blog) [singularity](https://en.wikipedia.org/wiki/Technological_singularity), the fact that powerful-computing-technology is coming is very clear. More technology-experts participating in society will make us all safer from, and *with*, these tools.

I also want to teach software development because [I believe it creates better 21st-century people](whylearncs.md). <--link to details

## Prophecy of the Future

As computer-technology improves, many (possibly most) people won't be able to find productive work. Computer-controlled tools will be able to do almost every task a human does, but better in many ways, certainly more cheaply. Humans will have computer-assisted jobs, taking advantage of hardware and software to multiply job effectiveness, letting one person do the job of *millions*. Automation will duplicate effort for free, while electronic communication will eliminate the need for duplication of effort, embeded sensors will track resources and reduce waste, electronic documentation will educate on-the-fly, and more. It's already happening, it will just happen more in the future.

In the future, conservatively, people with the right tech skills will be able to learn at double the speed of a normal person, and have double the mental output, in both quantity and quality (a greater-than-10x multiplier might be more accurate). Imagine doing any arithmetic problem without ever needing to touch a physical calculator, or commiting something to perfect memory as you are listening to it, or communicating with any person, in any language, without speaking or writing words, or even holding a device. This will be possible with tools like [Alter Ego from MIT](https://www.media.mit.edu/projects/alterego/overview/).

Imagine having an idea in the shower for how to write that next assignment, and before you've gotten out of the shower, you've dicated a first draft, reviewed it, and edited it down for brevity. Imagine hearing an interesting idea during a conversation, immidiately searching for a podcast, cutting to relevant new knowledge in the audio, listening to it at double speed (or more), and then responding in the conversation with that new knowledge in mind. The next revolution will not just be about what is possible, but where those possiblities will insert themselves in our lives. Within seconds of hearing an initiating idea, while continuously engaged in other tasks, you'll be able to have a machine do research and organization tasks for you on the back end. This will be possible by applying some (probably significant but certainly achievable) machine learning to Alter Ego.

Now imagine tech entrepreneurs using these technologies to unceasingly brainstorm, collaborate, and develop new mind-engagement tools. We know how radio and television sped up society, what will be the effect of an information interface like real-time [Augmented-Reality](https://www.youtube.com/watch?v=un4MmLZh9-g) [glasses](https://www.youtube.com/watch?v=mrXjGBsICuc)? What will the be the effect of direct brain-to-computer input-and-output enabled by [real-time brain imaging](https://www.ted.com/talks/mary_lou_jepsen_how_we_can_use_light_to_see_deep_inside_our_bodies_and_brains?language=en)?

Humans who know-how-to-use-computers-to-multiply-effort (what I call *wizards*) will be employable.

### What If I'm not a Wizard?

**"Impetus AR"** - a real-time re-education tool that will turn a population of disenfranchised meat-bags into a productive, organized work force. Imagine an Augmented Reality (AR) system that points a person toward productive actions, hopefully that benefit the causes the workers are aligned with. It gives someone a thing to do, something they believe in.

The system identifies tasks, directs users to tools and resources with visual/auditory/haptic cues, educates users with tutorials in Augmented Reality space, and logs the completion of tasks. Tutorials will eventually be created in real-time by neural-networks, to match specific real-life conditions, after neural networks learn to adapt human-made tutorials.

Step-by-step-instructions, will be given to anyone who doesn't know what to do next. Impetus AR will be like some the tools used by wizards, but more consumable by people without strong computer skills or disciplined personal drive. Organization of who does what task with what resources will be organized by another system. 

### Who or what will do the organizing?

**"Impetus Jobs"** - Imagine a combination of LinkedIn, TaskRabbit, SimAnt, Civilization, Slack, Reddit, and AlphaGo. It will gather and communicate with people, provide tools for communal decision making, use Strong-AI-prediction/analysis to develop plans for big groups to accomplish their collective goals, and balance work-load for maximum probability of success.

Impetus Jobs will have have information about citizens as a workers, including their skills, preferred kinds of work, possible moral/ethical perspectives, and life-goals. Workers will be matched with tasks, with worker advancement and "fit" in-mind. Tutorial tasks will be identified to improve skills if needed.

### Where will the project planning tools come from?

**"Impetus Project"** - Think of Trello combined with Microsoft Project and visualizations from a game like StarCraft. It's a dynamic database of work to do, created with game-like user-interface and game-development content-generation techniques. Tasks can be broken up explaining how to do them, and show compelling game-like visualizations to encourage and track progress.

Currently, the project model works with tasks in multiple dimensions, including TODO lists (which can be broken down into sub-lists of step-by-step instructions as work-breakdown-structures), GANTT charts (which allow tasks to be tracked by completion and resource usage), burndown charts (which visualize project completion rates), and resource & personnel spread-sheets. Each of these dimensions of tasks relate to the same project, with highly visible connections and trackable achievement.

Impetus Project also does predictive-analysis of projects using algorithms that improve estimation with data from performance. It won't have the impressive machine-learning "strong-AI", or deep communication-tool/social-media integration, that is what Impetus Jobs is for. The data models and project-specific user interfaces for Impetus Project will sit in a real-time strategy game.

### What game could be a basis for project management software?

**"Galactus"** - A real-time strategy game about seeking out partner-agents, with diverse skill sets and personalities (including simplified ethics), to accomplish complex goals. Think SimAnt combined with Dungeons&Dragons and Crusader Kings 2. The game mechanics will be implemented in an agent-based simulation. An AI system based on expert systems and behavior-trees emulating cognitive biases, and simplified ethics based on a computerized ethics-evaluation system I'm developing called ["Ethos"](http://codegiraffe.com/qeval/qual.html).

In the game, the player will influence the behavior of agents, like the god-games from bullfrog in days of old (Dungeon Keeper, Black and White). Goal-objects will be discovered and worked by an agent's skills. An agent working a skill improves the agent's skill score, which allows more complex goals to be completed later. Some goals have a dependency-graph that forces sub-goals to be accomplished first, sometimes in complex sequences. Agents recruit partner-agents with complementary skills and personalities to accomplish complex goals. This is done in an eco-system of other agent groups, who are all seeking to accomplish their own goals (sometimes conflicting or complementary) as well. This game will be a clear set of intellectual models for Impetus Project.

### How will human ethics be modeled in a game?

[**"Ethos"**](http://codegiraffe.com/qeval/qual.html) - A system that users can use to recognize areas of personal ethical growth. It's designed with input from a variety of texts that have idealistic and practical views on the human condition. It was originally developed as an evaluation system for students, to replace the A-through-F grade system.

There is more work to do here as well, but doing this work could have important implications on the future of strong AI. Imagine what a relief it would be to the tech world if a computer could systemize what it means to be a good person? Developing a deep framework to help a machine identify what is right and wrong behavior is an important next-step in humanity's advancement on the tech tree.

### Wait, what about the Augmented Reality piece, what will mature AR tools enough to build AR tutorials?

**"Builder VR"** - Think of this as *Minecraft-For-Real-Life*, teaching players to build houses with simulated foundations and connections to plumbing/sewage/electrical-grids/gas-lines, building around simulated geography, using simulated construction materials like planks, and rebar, and poured concrete, with context-sensitive building-code overlays, letting people practice building realistic modern buildings without physical costs.

Before creating Impetus AR, useful tutorials using VR must be developed and tested. An excellent domain for these tutorials would be Residential-Construction/Contracting. This industry has demand for a product like that, to enhance training and professionalism of it's workers. The success of Minecraft indicates that there is a shared mental-itch for this idea in the population.

### That's a lot to think about...

***"My Dragon"*** - The name you'll hear me use to refer to this plan.

*Ethos* is a moraly lofty goal, but seems like a good framework for implementing socially-constructive gameplay features in *Galactus* or *Builder VR*, and a necessary framework for the strong-AI in *Impetus Jobs*.

Developing *Galactus* or *Builder VR* as a game first could be sociologically valuable for young people, who are a risk to society when they don't integrate into works larger than themselves, which seems to be a sociolgical problem today. The game aspect could engage them long enough to teach some good mental models for engagement In Real Life (IRL). Sadly, game development is not a lucrative industry. However, enterprise software is.

*Impetus Project* is the commercial-training/enterprise software version of *Galactus*, selling a higher-profit-price-point version of that game to businesses/governments. The sales pitch could be "Many of your young employees *already know* this user interface, and they enjoy it. Many prospective employees are already trained." Learning-curve, user-interface, and lack-of-fun tend to be problems with enterprise-software and training-software, which *Impetus*'s roots as a game should address very nicely.

I think *Galactus*, *Builder VR*, and *Impetus Project* are all doable with today's technology.

*Impetus Jobs* is a natural evolution of *Impetus Project*: integrate social-media and job-boards, apply machine learning. I think *Impetus Jobs* needs some better machine-learning and machine-based creatively-constrained-decision-making techniques. I've got an idea for an ensemble machine-learning technique I'm toying with (Suffrag Ex Machina). I imagine those machine-decision-making-techniques will be developed by more people around 2022.

*Impetus AR* will need cheap AR hardware, very mature machine-vision, and significant amounts of AR-enhanced dynamic tutorial content (which *Builder VR* can act as a set of examples for). My guess is that *Impetus AR* will be commercially infeasible untill around 2025, because cheap projector glasses need to be available en-masse. AI that generates dynamic tutorial content seems like a tricky problem too, but I think it will become tractable with better generative-machine-learning algorithms.

I want to see these tools happen. Not having these tools in the near future seems like a really bad idea for humanity.

## Specific Short-term Goals
(This is essentially a public TODO list, most people reading the manifesto can stop here)

### Code Resources for Teaching & My Dragon
  * [Nonstandard Assets](https://github.com/mvaganov/galactus/tree/master/galactus/Assets/Nonstandard%20Assets) - a complimentary API to Unity providing common useful tools, which will be used in the other software projects.
    * Lines, Timer, ContingencyTrigger, CubeTools (3D math library)
    * CmdLine - a true command-line terminal replacement within Unity, including TTY color and position adjustment (TODO)
    * ControlledRigidbody (ground, air, space, novel-gravity controls), GravityObject, AIController
    * VR controller (teleport, climb-to-move, waddle-move... VRTK doing all of this?)
    * OMU - Object Modeling for Unity script (serialize/deserialize arbitrary data in JSON-like form)
    * MemoryPool
    * Noisy - re-doing PhysSound. Would be nice to get VoiceSynthesis in here too
    * "Story" Dialog system / scripted sequenced UI system
    * reflective object UI generator

### My Dragon (Galactus Phase)
* Nonstandard Assets
* 3D math code (command zones, AI, 3D voronoi, navmesh pathfinding)
  * in development in Unity3D. finding a good 3D-voronoi library would help a lot.
* spreadsheet UI
  * in development in Unity3D, with functional scripting engine. I just need to get this done. I'll probably open-source it when I do.
* Instant Runoff Voting tools (multiplayer decision making, AI)
  * need to convert .js code to C#, develop visuals, probably share that as a stand-alone data visualization app.
  * wrap around multiple ANN to create a recursive-ensemble technique (Sufrag Ex Machina)
* dynamic stat system
  * using common scripting system also used by spreadsheet UI may not scale well to thousands of objects. If I can generate C# objects with a runtime compiler, I'll have to create and use properties to replicate callback behavior around property updates.
* General AI (state-machines, steering behaviors)
  * should find a good API someone else wrote and add 3D math code to it. would be nice to find someone who is a pro at this.
* artifact building
  * agent can build roads, barriers, caches, monuments. need to fully spec this out in a design doc.
* VR controls
  * more experimentation required, need to integrate into movement/control UI. need to bone-up on VR UI standards, or find an expert. Maybe VRTK 4.0 will solve this?
* scripting system
  * need to make imperative code in OMU more java-script like.
* Project & Task system
  * use the scripted JSON-like datastructures (OMU) as the base. Already have examples of this working.
* Personnel & Resource system
  * requires spreadsheet UI, scripts, and stat/trait system for personnel to inform AI simulation. The RankedVote visual will help show and make-decisions-about resource/personnel usage.
* Project Management Visualizations (WBS, GANTT, burndown)
  * refresh and import old code.
* Customization UI
  * need to find and implement color picker, sprite loader/picker, simple model generator and basic texture mapper.
* Builder VR demo
  * this needs many more sub-bullet points
